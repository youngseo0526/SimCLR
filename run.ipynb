{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Number of workers: 12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler # learning rate decay\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of workers:\", NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Composition of data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLearningViewGenerator(object):\n",
    "    \"\"\"Take two random crops of one image as the query and key. n_views must be 2.\"\"\"\n",
    "    def __init__(self, base_transform, n_views=2):\n",
    "        self.base_transform = base_transform\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transform(x) for i in range(self.n_views)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "class GaussianBlur(object):\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        radias = kernel_size // 2\n",
    "        kernel_size = radias * 2 + 1\n",
    "        self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n",
    "                                stride=1, padding=0, bias=False, groups=3)\n",
    "        self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n",
    "                                stride=1, padding=0, bias=False, groups=3)\n",
    "        self.k = kernel_size\n",
    "        self.r = radias\n",
    "\n",
    "        self.blur = nn.Sequential(\n",
    "            nn.ReflectionPad2d(radias),\n",
    "            self.blur_h,\n",
    "            self.blur_v\n",
    "        )\n",
    "\n",
    "        self.pil_to_tensor = transforms.ToTensor()\n",
    "        self.tensor_to_pil = transforms.ToPILImage()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = self.pil_to_tensor(img).unsqueeze(0)\n",
    "\n",
    "        sigma = np.random.uniform(0.1, 2.0)\n",
    "        x = np.arange(-self.r, self.r + 1)\n",
    "        x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n",
    "        x = x / x.sum()\n",
    "        x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n",
    "\n",
    "        self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n",
    "        self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img = self.blur(img)\n",
    "            img = img.squeeze()\n",
    "\n",
    "        img = self.tensor_to_pil(img)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exceptions.exceptions import InvalidDatasetSelection\n",
    "\n",
    "class ContrastiveLearningDataset:\n",
    "    \n",
    "    def __init__(self, root_folder):\n",
    "        self.root_folder = root_folder\n",
    "\n",
    "    @staticmethod\n",
    "    def get_simclr_pipeline_transform(size):\n",
    "        color_jitter = transforms.ColorJitter(brightness=0.5,contrast=0.5,saturation=0.5,hue=0.1)\n",
    "        data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                              transforms.RandomGrayscale(p=0.2),\n",
    "                                              GaussianBlur(kernel_size=int(0.1 * size)),\n",
    "                                              transforms.ToTensor()])\n",
    "        return data_transforms\n",
    "\n",
    "    def get_dataset(self, name, n_views):\n",
    "        valid_datasets = {'cifar10': lambda: datasets.CIFAR10(self.root_folder, train=True,\n",
    "                                                              transform=ContrastiveLearningViewGenerator(\n",
    "                                                                  self.get_simclr_pipeline_transform(32),\n",
    "                                                                  n_views),\n",
    "                                                              download=True),\n",
    "\n",
    "                          'stl10': lambda: datasets.STL10(self.root_folder, split='unlabeled',\n",
    "                                                          transform=ContrastiveLearningViewGenerator(\n",
    "                                                              self.get_simclr_pipeline_transform(96),\n",
    "                                                              n_views),\n",
    "                                                          download=True)}\n",
    "\n",
    "        try:\n",
    "            dataset_fn = valid_datasets[name]\n",
    "        except KeyError:\n",
    "            raise InvalidDatasetSelection()\n",
    "        else:\n",
    "            return dataset_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SimCLR implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from utils import save_config_file, accuracy, save_checkpoint\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "class SimCLR(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args = kwargs['args']\n",
    "        self.model = kwargs['model'].to(self.args.device)\n",
    "        self.optimizer = kwargs['optimizer']\n",
    "        self.scheduler = kwargs['scheduler']\n",
    "        self.writer = SummaryWriter()\n",
    "        logging.basicConfig(filename=os.path.join(self.writer.log_dir, 'training.log'), level=logging.DEBUG)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.device)\n",
    "\n",
    "    def info_nce_loss(self, features):\n",
    "\n",
    "        labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.args.device)\n",
    "\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "        # assert similarity_matrix.shape == (\n",
    "        #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # discard the main diagonal from both: labels and similarities matrix\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # select and combine multiple positives\n",
    "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "        # select only the negatives the negatives\n",
    "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)\n",
    "\n",
    "        logits = logits / self.args.temperature\n",
    "        return logits, labels\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        scaler = GradScaler(enabled=self.args.fp16_precision)\n",
    "\n",
    "        # save config file\n",
    "        save_config_file(self.writer.log_dir, self.args)\n",
    "\n",
    "        n_iter = 0\n",
    "        logging.info(f\"Start SimCLR training for {self.args.epochs} epochs.\")\n",
    "        logging.info(f\"Training with gpu: {self.args.disable_cuda}.\")\n",
    "\n",
    "        for epoch_counter in range(self.args.epochs):\n",
    "            for images, _ in tqdm(train_loader):\n",
    "                images = torch.cat(images, dim=0)\n",
    "\n",
    "                images = images.to(self.args.device)\n",
    "\n",
    "                with autocast(enabled=self.args.fp16_precision):\n",
    "                    features = self.model(images)\n",
    "                    logits, labels = self.info_nce_loss(features)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                if n_iter % self.args.log_every_n_steps == 0:\n",
    "                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
    "                    self.writer.add_scalar('loss', loss, global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top1', top1[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top5', top5[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('learning_rate', self.scheduler.get_lr()[0], global_step=n_iter)\n",
    "\n",
    "                n_iter += 1\n",
    "\n",
    "            # warmup for the first 10 epochs\n",
    "            if epoch_counter >= 10:\n",
    "                self.scheduler.step()\n",
    "            logging.debug(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n",
    "    \n",
    "        logging.info(\"Training has finished.\")\n",
    "        # save model checkpoints\n",
    "        checkpoint_name = 'checkpoint_{:04d}.pth.tar'.format(self.args.epochs)\n",
    "        save_checkpoint({\n",
    "            'epoch': self.args.epochs,\n",
    "            'arch': self.args.arch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }, is_best=False, filename=os.path.join(self.writer.log_dir, checkpoint_name))\n",
    "        logging.info(f\"Model checkpoint and metadata has been saved at {self.writer.log_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initialzing components and arguments for SimCLR training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "        \"dataset_name\": 'cifar10',\n",
    "        \"data\": './CIFAR10',\n",
    "        \"arch\": 'resnet50',\n",
    "        \"workers\": 12,\n",
    "        \"epochs\": 400,\n",
    "        \"batch_size\": 512,\n",
    "        \"lr\": 0.0003,\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"seed=\": None,\n",
    "        \"disable_cuda\": \"\",\n",
    "        \"fp16_precision\": True,\n",
    "        \"out_dim\": 128,\n",
    "        \"log_every_n_steps\": 400,\n",
    "        \"temperature\": 0.07,\n",
    "        \"n_views\": 2,\n",
    "        \"gpu_index\": 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'cifar10',\n",
       " 'data': './CIFAR10',\n",
       " 'arch': 'resnet50',\n",
       " 'workers': 12,\n",
       " 'epochs': 400,\n",
       " 'batch_size': 512,\n",
       " 'lr': 0.0003,\n",
       " 'weight_decay': 0.0001,\n",
       " 'seed=': None,\n",
       " 'disable_cuda': '',\n",
       " 'fp16_precision': True,\n",
       " 'out_dim': 128,\n",
       " 'log_every_n_steps': 400,\n",
       " 'temperature': 0.07,\n",
       " 'n_views': 2,\n",
       " 'gpu_index': 0}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:26<00:00,  3.62it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.43it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.45it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.45it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.45it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.54it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.36it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.59it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.45it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.43it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.43it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.35it/s]\n",
      "100%|██████████| 97/97 [00:29<00:00,  3.33it/s]\n",
      "100%|██████████| 97/97 [00:29<00:00,  3.30it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.44it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.45it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.37it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.38it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.39it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.44it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.42it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.43it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.54it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.53it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.45it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.67it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.45it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.72it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.82it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.76it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.81it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.81it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.83it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.77it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.64it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.77it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.81it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.75it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.76it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.82it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.81it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.82it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.81it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.75it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.82it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.44it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.53it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.54it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.53it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.40it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.53it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.55it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.42it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.45it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.43it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.40it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.53it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.54it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.56it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.54it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.50it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.56it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.36it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.35it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.38it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.42it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.38it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.42it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.45it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.44it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.53it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.54it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.48it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.53it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.51it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.47it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.53it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.52it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.56it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.75it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.78it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.69it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.78it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.77it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.58it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.62it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.61it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.68it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.70it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.56it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.56it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.56it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.62it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.58it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.67it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.63it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.60it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.58it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.64it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.58it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.66it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.62it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.63it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.78it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.77it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.81it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.78it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.77it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.63it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.64it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.75it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.75it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.61it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.70it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.71it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.74it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.75it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.80it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.77it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.76it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.76it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.78it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.70it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.63it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.67it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.71it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.73it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.77it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.78it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.70it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.67it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.59it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.70it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.77it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.59it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.56it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.57it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.65it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.73it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.73it/s]\n",
      "100%|██████████| 97/97 [00:26<00:00,  3.61it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 97/97 [00:25<00:00,  3.79it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.59it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.45it/s]\n",
      "100%|██████████| 97/97 [00:30<00:00,  3.21it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.42it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.35it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.41it/s]\n",
      "100%|██████████| 97/97 [00:29<00:00,  3.34it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.41it/s]\n",
      "100%|██████████| 97/97 [00:29<00:00,  3.29it/s]\n",
      "100%|██████████| 97/97 [00:27<00:00,  3.49it/s]\n",
      "100%|██████████| 97/97 [00:28<00:00,  3.39it/s]\n",
      " 49%|████▉     | 48/97 [00:17<00:17,  2.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1336043/1078806747.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1336043/1078806747.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msimclr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimCLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0msimclr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1336043/781477202.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch.backends.cudnn as cudnn\n",
    "from model.resnet import ResNetSimCLR\n",
    "\n",
    "def main():\n",
    "    assert args.n_views == 2\n",
    "    # check if gpu training is available\n",
    "    if torch.cuda.is_available():\n",
    "        args.device = torch.device('cuda')\n",
    "        cudnn.deterministic = True\n",
    "        cudnn.benchmark = True\n",
    "    else:\n",
    "        args.device = torch.device('cpu')\n",
    "        args.gpu_index = -1\n",
    "\n",
    "\n",
    "    dataset = ContrastiveLearningDataset(args.data)\n",
    "\n",
    "    train_dataset = dataset.get_dataset(args.dataset_name, args.n_views)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=args.workers, pin_memory=True, drop_last=True)\n",
    "        \n",
    "    model = ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0, last_epoch=-1)\n",
    "\n",
    "    #  It’s a no-op if the 'gpu_index' argument is a negative integer or None.\n",
    "    with torch.cuda.device(args.gpu_index):\n",
    "        simclr = SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "        simclr.train(train_loader)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('simclr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f46d7893190d57e75cddf31b2433c354470ab72d7675cbebc7f98024251002d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
