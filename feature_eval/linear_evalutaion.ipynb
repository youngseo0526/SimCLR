{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/SimCLR/blob/simclr-refactor/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YUemQib7ZE4D"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSgRE1CcLqdS",
        "outputId": "48a2ae15-f672-495b-8d43-9a23b85fa3b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: gdown in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (4.5.3)\n",
            "Requirement already satisfied: requests[socks] in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from gdown) (2.28.1)\n",
            "Requirement already satisfied: filelock in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: six in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from gdown) (4.11.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NOIJEui1ZziV"
      },
      "outputs": [],
      "source": [
        "def get_file_id_by_model(folder_name):\n",
        "  file_id = {'resnet18_100-epochs_stl10': '14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF',\n",
        "             'resnet18_100-epochs_cifar10': '1lc2aoVtrAetGn0PnTkOyFzPCIucOJq7C',\n",
        "             'resnet50_50-epochs_stl10': '1ByTKAUsdm_X7tLcii6oAEl5qFRqRMZSu'}\n",
        "  return file_id.get(folder_name, \"Model not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7YMxsvEZMrX",
        "outputId": "59475430-69d2-45a2-b61b-ae755d5d6e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resnet18_100-epochs_cifar10 1lc2aoVtrAetGn0PnTkOyFzPCIucOJq7C\n"
          ]
        }
      ],
      "source": [
        "folder_name = 'resnet18_100-epochs_cifar10'\n",
        "file_id = get_file_id_by_model(folder_name)\n",
        "print(folder_name, file_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWZ8fet_YoJm",
        "outputId": "fbaeb858-221b-4d1b-dd90-001a6e713b75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lc2aoVtrAetGn0PnTkOyFzPCIucOJq7C\n",
            "To: /home/sieun/Desktop/simCLR/feature_eval/resnet18_100-epochs_cifar10.zip\n",
            "100%|██████████| 101M/101M [00:03<00:00, 26.5MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  resnet18_100-epochs_cifar10.zip\n",
            "  inflating: checkpoint_0100.pth.tar  \n",
            "  inflating: config.yml              \n",
            "  inflating: events.out.tfevents.1610901418.4cb2c837708d.2683796.0  \n",
            "  inflating: run.log                 \n",
            "checkpoint_0100.pth.tar\n",
            "Code_review_mini_batch_logistic_regression_evaluator.ipynb\n",
            "config.yml\n",
            "contrastive_learning_framework.jpg\n",
            "data_aug.jpg\n",
            "events.out.tfevents.1610901418.4cb2c837708d.2683796.0\n",
            "infonce_loss.jpg\n",
            "mini_batch_logistic_regression_evaluator.ipynb\n",
            "resnet18_100-epochs_cifar10.zip\n",
            "run.log\n"
          ]
        }
      ],
      "source": [
        "# download and extract model files\n",
        "os.system('gdown https://drive.google.com/uc?id={}'.format(file_id))\n",
        "os.system('unzip {}'.format(folder_name))\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3_nypQVEv-hn"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDfbL3w_Z0Od",
        "outputId": "7532966e-1c4a-4641-c928-4cda14c53389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BfIPl0G6_RrT"
      },
      "outputs": [],
      "source": [
        "def get_stl10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "  train_dataset = datasets.STL10('./data', split='train', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=0, drop_last=False, shuffle=shuffle)\n",
        "  \n",
        "  test_dataset = datasets.STL10('./data', split='test', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=10, drop_last=False, shuffle=shuffle)\n",
        "  return train_loader, test_loader\n",
        "\n",
        "def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "  train_dataset = datasets.CIFAR10('./data', train=True, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=0, drop_last=False, shuffle=shuffle)\n",
        "  \n",
        "  test_dataset = datasets.CIFAR10('./data', train=False, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=10, drop_last=False, shuffle=shuffle)\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6N8lYkbmDTaK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sieun/anaconda3/envs/simclr/lib/python3.7/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "with open(os.path.join('./config.yml')) as file:\n",
        "  config = yaml.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a18lPD-tIle6"
      },
      "outputs": [],
      "source": [
        "if config.arch == 'resnet18':\n",
        "  model = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)\n",
        "elif config.arch == 'resnet50':\n",
        "  model = torchvision.models.resnet50(pretrained=False, num_classes=10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4AIfgq41GuTT"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load('checkpoint_0100.pth.tar', map_location=device)\n",
        "state_dict = checkpoint['state_dict']\n",
        "\n",
        "for k in list(state_dict.keys()):\n",
        "\n",
        "  if k.startswith('backbone.'):\n",
        "    if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "      # remove prefix\n",
        "      state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "  del state_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VVjA83PPJYWl"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for ResNet:\n\tsize mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_950763/4029594966.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_keys\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'fc.weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fc.bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/simclr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tsize mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1])."
          ]
        }
      ],
      "source": [
        "log = model.load_state_dict(state_dict, strict=False)\n",
        "assert log.missing_keys == ['fc.weight', 'fc.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "149b9ce8fb68473a837a77431c12281a",
            "88cd3db2831e4c13a4a634709700d6b2",
            "a88c31d74f5c40a2b24bcff5a35d216c",
            "60c6150177694717a622936b830427b5",
            "dba019efadee4fdc8c799f309b9a7e70",
            "5901c2829a554c8ebbd5926610088041",
            "957362a11d174407979cf17012bf9208",
            "a4f82234388e4701a02a9f68a177193a"
          ]
        },
        "id": "_GC0a14uWRr6",
        "outputId": "4c2558db-921c-425e-f947-6cc746d8c749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "170500096it [00:22, 7643442.04it/s]                               \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Dataset: cifar10\n"
          ]
        }
      ],
      "source": [
        "if config.dataset_name == 'cifar10':\n",
        "  train_loader, test_loader = get_cifar10_data_loaders(download=True)\n",
        "elif config.dataset_name == 'stl10':\n",
        "  train_loader, test_loader = get_stl10_data_loaders(download=True)\n",
        "print(\"Dataset:\", config.dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pYT_KsM0Mnnr"
      },
      "outputs": [],
      "source": [
        "# freeze all layers but the last fc\n",
        "for name, param in model.named_parameters():\n",
        "    if name not in ['fc.weight', 'fc.bias']:\n",
        "        param.requires_grad = False\n",
        "\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "assert len(parameters) == 2  # fc.weight, fc.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aPVh1S_eMRDU"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.0008)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edr6RhP2PdVq"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOder0dAMI7X",
        "outputId": "5f723b91-5a5e-43eb-ca01-a9b5ae2f1346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 1\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 2\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 3\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 4\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 5\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 6\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 7\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 8\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 9\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 10\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 11\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 12\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 13\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 14\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 15\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 16\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 17\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 18\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 19\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 20\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 21\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 22\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 23\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 24\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 25\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 26\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 27\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 28\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 29\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 30\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 31\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 32\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 33\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 34\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 35\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 36\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 37\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 38\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 39\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 40\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 41\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 42\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 43\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 44\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 45\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 46\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 47\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 48\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 49\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 50\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 51\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 52\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 53\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 54\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 55\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 56\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 57\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 58\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 59\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 60\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 61\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 62\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 63\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 64\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 65\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 66\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 67\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 68\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 69\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 70\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 71\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 72\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 73\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 74\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 75\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 76\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 77\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 78\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 79\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 80\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 81\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 82\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 83\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 84\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 85\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 86\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 87\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 88\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 89\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 90\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 91\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 92\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 93\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 94\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 95\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 96\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 97\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 98\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n",
            "Epoch 99\tTop1 Train accuracy 9.56473159790039\tTop1 Test accuracy: 9.388787269592285\tTop5 test acc: 49.32732009887695\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  top1_train_accuracy = 0\n",
        "  for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "    loss = criterion(logits, y_batch)\n",
        "    top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "    top1_train_accuracy += top1[0]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  top1_train_accuracy /= (counter + 1)\n",
        "  top1_accuracy = 0\n",
        "  top5_accuracy = 0\n",
        "  for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "  \n",
        "    top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
        "    top1_accuracy += top1[0]\n",
        "    top5_accuracy += top5[0]\n",
        "  \n",
        "  top1_accuracy /= (counter + 1)\n",
        "  top5_accuracy /= (counter + 1)\n",
        "  print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.6 ('simclr')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "5f46d7893190d57e75cddf31b2433c354470ab72d7675cbebc7f98024251002d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "149b9ce8fb68473a837a77431c12281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a88c31d74f5c40a2b24bcff5a35d216c",
              "IPY_MODEL_60c6150177694717a622936b830427b5"
            ],
            "layout": "IPY_MODEL_88cd3db2831e4c13a4a634709700d6b2"
          }
        },
        "5901c2829a554c8ebbd5926610088041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c6150177694717a622936b830427b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f82234388e4701a02a9f68a177193a",
            "placeholder": "​",
            "style": "IPY_MODEL_957362a11d174407979cf17012bf9208",
            "value": " 2640404480/? [00:51&lt;00:00, 32685718.58it/s]"
          }
        },
        "88cd3db2831e4c13a4a634709700d6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957362a11d174407979cf17012bf9208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f82234388e4701a02a9f68a177193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88c31d74f5c40a2b24bcff5a35d216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5901c2829a554c8ebbd5926610088041",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dba019efadee4fdc8c799f309b9a7e70",
            "value": 1
          }
        },
        "dba019efadee4fdc8c799f309b9a7e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
